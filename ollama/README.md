## Ollama-Based Commit Message Generator

Ollama LLM (Large Language Model)ê³¼ FastAPIë¥¼ ì—°ë™í•˜ì—¬ **git diff**ë¥¼ ë¶„ì„í•˜ê³  ë¬¸ë§¥ì— ë§ëŠ” ì»¤ë°‹ ë©”ì‹œì§€ë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•˜ëŠ” API ì„œë²„ì…ë‹ˆë‹¤. Conventional Commits í˜•ì‹ì„ ì¤€ìˆ˜í•©ë‹ˆë‹¤.  
This is an API server that integrates Ollama LLM with FastAPI to analyze **git diff** and automatically generate context-aware commit messages in the Conventional Commits format.

---

## âœ¨ ì£¼ìš” ê¸°ëŠ¥ | Key Features

- **Ollama ì—°ë™**: ë¡œì»¬ ë˜ëŠ” ì›ê²© Ollama ì¸ìŠ¤í„´ìŠ¤ í™œìš©  
  Integration with local or remote Ollama instances
- **FastAPI ê¸°ë°˜ ì„œë²„**: API ì—”ë“œí¬ì¸íŠ¸ë¥¼ í†µí•´ ì»¤ë°‹ ë©”ì‹œì§€ ìƒì„± ìš”ì²­ ì²˜ë¦¬  
  FastAPI-based server to handle commit message generation requests via API endpoints
- **ìœ ì—°í•œ ëª¨ë¸ ì„ íƒ**: `llama3`, `qwen3:8b` ë“± ë‹¤ì–‘í•œ Ollama ëª¨ë¸ ì§€ì› (ê¸°ë³¸: `llama3`)  
  Flexible model selection, supporting various Ollama models like `llama3`, `qwen3:8b` (default: `llama3`)
- **ë‹¤êµ­ì–´ ì§€ì›**: ì»¤ë°‹ ë©”ì‹œì§€ ìƒì„± ì–¸ì–´ ì„ íƒ ê°€ëŠ¥ (ì˜ˆ: `ko`, `en`)  
  Multilingual support: choose the language for generated commit messages (e.g., `ko`, `en`)
- **Conventional Commits**: í‘œì¤€í™”ëœ ì»¤ë°‹ ë©”ì‹œì§€ í˜•ì‹ ì¤€ìˆ˜  
  Adherence to the Conventional Commits standard

---

## ğŸ“¦ êµ¬ì„± íŒŒì¼ | Files

- **app.py**: FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œì§ (Ollama ì—°ë™, í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬, API ì—”ë“œí¬ì¸íŠ¸)  
  FastAPI application logic (Ollama integration, prompt handling, API endpoints)
- **requirements.txt**: Python íŒ¨í‚¤ì§€ ì˜ì¡´ì„± ëª©ë¡  
  List of Python package dependencies

---

## ğŸš€ ì‹œì‘í•˜ê¸° | Getting Started

### 1. ì‚¬ì „ ì¤€ë¹„ ì‚¬í•­ | Prerequisites

- **Python 3.8 ì´ìƒ** ì„¤ì¹˜  
  Python 3.8 or higher installed
- **Ollama ì„¤ì¹˜ ë° ì‹¤í–‰**: [Ollama ê³µì‹ ì›¹ì‚¬ì´íŠ¸](https://ollama.com/) ì°¸ì¡°  
  Ollama installed and running: refer to the [Ollama official website](https://ollama.com/)

### 2. Ollama ëª¨ë¸ ë‹¤ìš´ë¡œë“œ | Download Ollama Models

ì„œë²„ì—ì„œ ì‚¬ìš©í•  Ollama ëª¨ë¸ì„ ë¯¸ë¦¬ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤. ê¸°ë³¸ì ìœ¼ë¡œ `llama3` ëª¨ë¸ì„ ì‚¬ìš©í•˜ì§€ë§Œ, ë‹¤ë¥¸ ëª¨ë¸ë„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
Download the Ollama models you intend to use with the server. By default, it uses the `llama3` model, but others can be used.

```bash
ollama pull llama3
ollama pull qwen3:8b # ì˜ˆì‹œ: ë‹¤ë¥¸ ëª¨ë¸ ì‚¬ìš© ì‹œ
```

### 3. ì„¤ì¹˜ | Installation

#### ê°€ìƒ í™˜ê²½ ì„¤ì • (ê¶Œì¥) | Setting up a Virtual Environment (Recommended)

```bash
python3 -m venv venv
source venv/bin/activate  # macOS/Linux
# venv\Scripts\activate  # Windows
```

#### ì˜ì¡´ì„± ì„¤ì¹˜ | Installing Dependencies

```bash
pip install -r requirements.txt
```

---

## âš™ï¸ ì‹¤í–‰ ë°©ë²• | How to Run

### ë¡œì»¬ì—ì„œ ì§ì ‘ ì‹¤í–‰ | Running Directly Locally

FastAPI ê°œë°œ ì„œë²„ë¥¼ ì‚¬ìš©í•˜ì—¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.

```bash
uvicorn ollama.server.app:app --reload --host 0.0.0.0 --port 8000
```

- `--reload`: ì½”ë“œ ë³€ê²½ ì‹œ ìë™ ì¬ì‹œì‘
- `--host 0.0.0.0`: ëª¨ë“  ë„¤íŠ¸ì›Œí¬ ì¸í„°í˜ì´ìŠ¤ì—ì„œ ì ‘ì† í—ˆìš©
- `--port 8000`: ì‚¬ìš©í•  í¬íŠ¸ ë²ˆí˜¸ (ê¸°ë³¸ê°’)

ì„œë²„ê°€ ì‹¤í–‰ë˜ë©´ `http://localhost:8000/docs` ì—ì„œ API ë¬¸ì„œë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## ğŸ“– API ì‚¬ìš©ë²• | API Usage

### `/generate-commit-message` (POST)

Git diff ë‚´ìš©ì„ ë°›ì•„ Conventional Commit í˜•ì‹ì˜ ë©”ì‹œì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

**Request Body:**

```json
{
  "diff": "your git diff content here"
}
```

**Query Parameters:**

- `model` (str, optional): ì‚¬ìš©í•  Ollama ëª¨ë¸ ì´ë¦„. ê¸°ë³¸ê°’: `llama3`. (ì˜ˆ: `qwen3:8b`)
- `lang` (str, optional): ìƒì„±ë  ì»¤ë°‹ ë©”ì‹œì§€ì˜ ì–¸ì–´. ê¸°ë³¸ê°’: `ko`. (ì˜ˆ: `en`, `ja`)

**Example Request (curl):**

```bash
curl -X POST "http://localhost:8000/generate-commit-message?model=llama3&lang=ko" \
     -H "Content-Type: application/json" \
     -d '{
       "diff": "--- a/test.txt\n+++ b/test.txt\n@@ -1 +1 @@\n-hello\n+hello world"
     }'
```

**Example Response:**

```json
{
  "commit_message": "feat(test): add world to hello"
}
```

---

## ğŸ› ï¸ ê¸°ì—¬ ë°©ë²• | How to Contribute

ì´ í”„ë¡œì íŠ¸ì— ê¸°ì—¬í•˜ê³  ì‹¶ìœ¼ì‹œë©´, [Pull Request](https://github.com/liminteger/auto-commit-message/pulls)ë¥¼ ë³´ë‚´ì£¼ì„¸ìš”.  
If you'd like to contribute to this project, feel free to send a [Pull Request](https://github.com/liminteger/auto-commit-message/pulls).

### ì•„ì´ë””ì–´ | Ideas

- íŠ¹ì • íŒŒì¼ ë³€ê²½ì— ëŒ€í•œ ì»¤ë°‹ ë©”ì‹œì§€ ìƒì„± ê·œì¹™ ì¶”ê°€
- ë‹¤ì–‘í•œ LLM ëª¨ë¸ ì§€ì› í™•ëŒ€
- í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê°œì„ ì„ í†µí•œ ë©”ì‹œì§€ í’ˆì§ˆ í–¥ìƒ

---

## ğŸ“ ë¬¸ì œë‚˜ ì§ˆë¬¸ì´ ìˆë‹¤ë©´ | Issues or Questions

ë¬¸ì œë‚˜ ì§ˆë¬¸ì´ ìˆìœ¼ë©´ [ì´ìŠˆ í˜ì´ì§€](https://github.com/liminteger/auto-commit-message/issues)ì—ì„œ ì•Œë ¤ì£¼ì„¸ìš”.  
If you encounter any issues or have questions, feel free to raise them on the [Issues page](https://github.com/liminteger/auto-commit-message/issues).

---

## ğŸ“„ ë¼ì´ì„ ìŠ¤ | License

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ë¥¼ ë”°ë¦…ë‹ˆë‹¤.  
This project is licensed under the MIT License.
